# ğŸ³ Instrucciones para Docker

## âœ… Checklist Antes de Ejecutar

### 1. Modelos Entrenados
```bash
cd modelo_ML
# Si no tienes modelos, entrÃ©nalos:
python scripts/generate_synthetic_dataset.py
python train_model.py
```

**Verificar que existan:**
- `models/rf_model.pkl` âœ“
- `models/scaler.pkl` âœ“
- `models/iso_model.pkl` (opcional)

### 2. Configurar Variables de Entorno

Edita el archivo `.env` en `PF_backend/ProyectoFinal_Backend/`:

```env
# Base de datos (ya deberÃ­a estar)
DATABASE_URL="postgresql://postgres:postgres@db:5432/ids?schema=public"
NATS_URL="nats://nats:4222"
PORT=8080
NODE_ENV=production

# â­ AGREGAR ESTAS LÃNEAS:
OPENAI_API_KEY=tu-api-key-aqui
ML_INTERVAL_SECONDS=10
EVE_JSON_PATH=/var/log/suricata/eve.json
```

### 3. Verificar Estructura

```
modelo_ML/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ rf_model.pkl    âœ“ Debe existir
â”‚   â””â”€â”€ scaler.pkl      âœ“ Debe existir
â”œâ”€â”€ data/
â”‚   â””â”€â”€ dataset.csv     (opcional, solo para referencia)
â”œâ”€â”€ Dockerfile          âœ“
â”œâ”€â”€ docker-entrypoint.sh âœ“
â””â”€â”€ pipeline_monitor.py âœ“
```

## ğŸš€ Ejecutar

```bash
cd PF_backend/ProyectoFinal_Backend
docker compose up --build
```

## ğŸ“Š Verificar que Funciona

### 1. Ver logs del servicio ML:
```bash
docker compose logs -f ml-pipeline
```

DeberÃ­as ver:
```
[INFO] âœ… Backend estÃ¡ disponible
[INFO] Iniciando pipeline de monitoreo...
============================================================
PIPELINE DE MONITOREO DE CRYPTOJACKING
============================================================
```

### 2. Verificar que el servicio estÃ© corriendo:
```bash
docker compose ps
```

DeberÃ­as ver `ml-pipeline` con estado `Up`.

### 3. Verificar que los modelos se cargaron:
```bash
docker compose logs ml-pipeline | grep "Modelo cargado"
```

## ğŸ”§ SoluciÃ³n de Problemas

### Error: "Modelos no encontrados"
**SoluciÃ³n**: Los modelos deben estar en `models/` antes de construir la imagen, o se montarÃ¡n desde el volumen.

**OpciÃ³n 1**: Copiar modelos al volumen despuÃ©s de construir:
```bash
docker compose run --rm ml-pipeline python train_model.py
```

**OpciÃ³n 2**: Montar modelos desde el host:
Edita `docker-compose.yml` y agrega:
```yaml
volumes:
  - ./modelo_ML/models:/app/models:ro
```

### Error: "OPENAI_API_KEY no estÃ¡ configurada"
**SoluciÃ³n**: Agrega la variable al archivo `.env` del backend.

### Error: "Backend no estÃ¡ disponible"
**SoluciÃ³n**: Verifica que el servicio `app` estÃ© corriendo:
```bash
docker compose logs app
```

## ğŸ“ Notas Importantes

1. **Los modelos se persisten en el volumen `ml_models`** - Si entrenas nuevos modelos dentro del contenedor, se guardarÃ¡n ahÃ­.

2. **El pipeline espera automÃ¡ticamente al backend** - No necesitas iniciarlo manualmente.

3. **Los volÃºmenes son persistentes** - Los modelos y datos se mantienen entre reinicios.

4. **El servicio se reinicia automÃ¡ticamente** - Si falla, Docker lo reiniciarÃ¡.

